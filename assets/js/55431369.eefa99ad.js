"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[3046],{324:(a,l,t)=>{t.r(l),t.d(l,{assets:()=>r,contentTitle:()=>s,default:()=>m,frontMatter:()=>n,metadata:()=>o,toc:()=>g});var e=t(5893),i=t(1151);t(5124),t(5860);const n={slug:"what-is-ollama",title:"What is Ollama? A shallow dive into running LLMs locally",authors:["ichung"],tags:["ollama","llama","chat","AI","LLM","ML","chatbot","local"],image:"./tiny-llama.png"},s=void 0,o={permalink:"/blog/what-is-ollama",source:"@site/blog/2024-01-07-ollama/index.md",title:"What is Ollama? A shallow dive into running LLMs locally",description:"Being able to run LLMs locally and easily is truly a game changer. I have heard about Ollama before and decided to take a look at it this past weekend.",date:"2024-01-07T00:00:00.000Z",formattedDate:"January 7, 2024",tags:[{label:"ollama",permalink:"/blog/tags/ollama"},{label:"llama",permalink:"/blog/tags/llama"},{label:"chat",permalink:"/blog/tags/chat"},{label:"AI",permalink:"/blog/tags/ai"},{label:"LLM",permalink:"/blog/tags/llm"},{label:"ML",permalink:"/blog/tags/ml"},{label:"chatbot",permalink:"/blog/tags/chatbot"},{label:"local",permalink:"/blog/tags/local"}],readingTime:2.62,hasTruncateMarker:!0,authors:[{name:"Isaac Chung",title:"Senior Research Engineer @ Clarifai",url:"https://isaac-chung.github.io",imageURL:"https://github.com/isaac-chung.png",key:"ichung"}],frontMatter:{slug:"what-is-ollama",title:"What is Ollama? A shallow dive into running LLMs locally",authors:["ichung"],tags:["ollama","llama","chat","AI","LLM","ML","chatbot","local"],image:"./tiny-llama.png"},unlisted:!1,prevItem:{title:"When Quantized Models Still Don't Fit",permalink:"/blog/quantized-models-dont-fit"}},r={image:t(3951).Z,authorsImageUrls:[void 0]},g=[];function h(a){const l={a:"a",admonition:"admonition",em:"em",li:"li",p:"p",ul:"ul",...(0,i.a)(),...a.components};return(0,e.jsxs)(e.Fragment,{children:[(0,e.jsxs)(l.p,{children:["Being able to run LLMs locally and ",(0,e.jsx)(l.em,{children:"easily"})," is truly a game changer. I have heard about ",(0,e.jsx)(l.a,{href:"https://github.com/jmorganca/ollama",children:"Ollama"})," before and decided to take a look at it this past weekend."]}),"\n",(0,e.jsx)(l.admonition,{title:"Key questions I'll address are:",type:"tip",children:(0,e.jsxs)(l.ul,{children:["\n",(0,e.jsx)(l.li,{children:"Why is running LLMs locally becoming a hot thang"}),"\n",(0,e.jsx)(l.li,{children:"What is Ollama?"}),"\n",(0,e.jsx)(l.li,{children:"Should you use Ollama?"}),"\n"]})})]})}function m(a={}){const{wrapper:l}={...(0,i.a)(),...a.components};return l?(0,e.jsx)(l,{...a,children:(0,e.jsx)(h,{...a})}):h(a)}},5124:(a,l,t)=>{t.d(l,{Z:()=>s});var e=t(7294),i=t(9276),n=t(5893);function s(a){let{image:l,alt:s,caption:o}=a;const[r,g]=(0,e.useState)({width:0,height:0}),h=o.split("\\n").map(((a,l,t)=>(0,n.jsxs)(e.Fragment,{children:[a,l<t.length-1&&(0,n.jsx)("br",{})]},l)));return(0,e.useEffect)((()=>{const a=new Image;a.onload=()=>{g({width:a.naturalWidth,height:a.naturalHeight})},a.src=l;const e=new i.Z({gallery:"#figure-gallery",children:"a",pswpModule:()=>t.e(5826).then(t.bind(t,7766))});return e.init(),()=>{e.destroy()}}),[l]),(0,n.jsxs)("figure",{style:{border:"1px dashed rgba(0, 0, 0, .1)",padding:0,margin:0,marginBottom:20,borderRadius:"15px",textAlign:"right"},id:"figure-gallery",children:[(0,n.jsx)("a",{href:l,"data-pswp-width":r.width,"data-pswp-height":r.height,children:(0,n.jsx)("img",{src:l,alt:s,style:{maxWidth:"100%",height:"auto"}})}),(0,n.jsx)("hr",{style:{margin:"5px 0",backgroundColor:"rgba(0, 0, 0, .2)"}}),(0,n.jsx)("figcaption",{style:{marginTop:"0.5em",marginBottom:"0.5em",marginRight:"1em",textAlign:"right",fontSize:"0.8em"},children:h})]})}},3951:(a,l,t)=>{t.d(l,{Z:()=>e});const e=t.p+"assets/images/tiny-llama-eab3b5a919157baa1f102158a2858f98.png"},5860:(a,l,t)=>{t.d(l,{Z:()=>e});const e=t.p+"assets/images/tiny-llama-eab3b5a919157baa1f102158a2858f98.png"}}]);