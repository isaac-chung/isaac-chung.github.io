"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[46],{324:(a,l,t)=>{t.r(l),t.d(l,{assets:()=>r,contentTitle:()=>o,default:()=>g,frontMatter:()=>i,metadata:()=>s,toc:()=>c});var e=t(5893),n=t(1151);t(5124),t(5860);const i={slug:"what-is-ollama",title:"What is Ollama? A shallow dive into running LLMs locally",authors:["ichung"],tags:["ollama","llama","chat","AI","LLM","ML","chatbot","local"],image:"./tiny-llama.png"},o=void 0,s={permalink:"/blog/what-is-ollama",source:"@site/blog/2024-01-07-ollama/index.md",title:"What is Ollama? A shallow dive into running LLMs locally",description:"Being able to run LLMs locally and easily is truly a game changer. I have heard about Ollama before and decided to take a look at it this past weekend.",date:"2024-01-07T00:00:00.000Z",formattedDate:"January 7, 2024",tags:[{label:"ollama",permalink:"/blog/tags/ollama"},{label:"llama",permalink:"/blog/tags/llama"},{label:"chat",permalink:"/blog/tags/chat"},{label:"AI",permalink:"/blog/tags/ai"},{label:"LLM",permalink:"/blog/tags/llm"},{label:"ML",permalink:"/blog/tags/ml"},{label:"chatbot",permalink:"/blog/tags/chatbot"},{label:"local",permalink:"/blog/tags/local"}],readingTime:2.6166666666666667,hasTruncateMarker:!0,authors:[{name:"Isaac Chung",title:"Senior Research Engineer @ Clarifai",url:"https://isaac-chung.github.io",imageURL:"https://github.com/isaac-chung.png",key:"ichung"}],frontMatter:{slug:"what-is-ollama",title:"What is Ollama? A shallow dive into running LLMs locally",authors:["ichung"],tags:["ollama","llama","chat","AI","LLM","ML","chatbot","local"],image:"./tiny-llama.png"},unlisted:!1},r={image:t(3951).Z,authorsImageUrls:[void 0]},c=[];function m(a){const l={a:"a",admonition:"admonition",em:"em",li:"li",p:"p",ul:"ul",...(0,n.a)(),...a.components};return(0,e.jsxs)(e.Fragment,{children:[(0,e.jsxs)(l.p,{children:["Being able to run LLMs locally and ",(0,e.jsx)(l.em,{children:"easily"})," is truly a game changer. I have heard about ",(0,e.jsx)(l.a,{href:"https://github.com/jmorganca/ollama",children:"Ollama"})," before and decided to take a look at it this past weekend."]}),"\n",(0,e.jsx)(l.admonition,{title:"Key questions I'll address are:",type:"tip",children:(0,e.jsxs)(l.ul,{children:["\n",(0,e.jsx)(l.li,{children:"Why is running LLMs locally becoming a hot thang"}),"\n",(0,e.jsx)(l.li,{children:"What is Ollama?"}),"\n",(0,e.jsx)(l.li,{children:"Should you use Ollama?"}),"\n"]})})]})}function g(a={}){const{wrapper:l}={...(0,n.a)(),...a.components};return l?(0,e.jsx)(l,{...a,children:(0,e.jsx)(m,{...a})}):m(a)}},5124:(a,l,t)=>{t.d(l,{Z:()=>i});var e=t(7294),n=t(5893);const i=a=>{let{image:l,alt:t,caption:i}=a;const o=i.split("\\n").map(((a,l,t)=>(0,n.jsxs)(e.Fragment,{children:[a,l<t.length-1&&(0,n.jsx)("br",{})]},l)));return(0,n.jsxs)("figure",{style:{border:"1px dashed rgba(0, 0, 0, .1)",padding:0,margin:0,marginBottom:20,borderRadius:"15px",textAlign:"right"},children:[(0,n.jsx)("img",{src:l,alt:t,style:{maxWidth:"100%",height:"auto"}}),(0,n.jsx)("hr",{style:{margin:"5px 0",backgroundColor:"rgba(0, 0, 0, .2)"}}),(0,n.jsx)("figcaption",{style:{marginTop:"0.5em",marginBottom:"0.5em",marginRight:"1em",textAlign:"right",fontSize:"0.8em"},children:o})]})}},3951:(a,l,t)=>{t.d(l,{Z:()=>e});const e=t.p+"assets/images/tiny-llama-eab3b5a919157baa1f102158a2858f98.png"},5860:(a,l,t)=>{t.d(l,{Z:()=>e});const e=t.p+"assets/images/tiny-llama-eab3b5a919157baa1f102158a2858f98.png"},1151:(a,l,t)=>{t.d(l,{Z:()=>s,a:()=>o});var e=t(7294);const n={},i=e.createContext(n);function o(a){const l=e.useContext(i);return e.useMemo((function(){return"function"==typeof a?a(l):{...l,...a}}),[l,a])}function s(a){let l;return l=a.disableParentContext?"function"==typeof a.components?a.components(n):a.components||n:o(a.components),e.createElement(i.Provider,{value:l},a.children)}}}]);