"use strict";(self.webpackChunkblog=self.webpackChunkblog||[]).push([[2535],{5641:l=>{l.exports=JSON.parse('{"title":"Recent posts","items":[{"title":"All about Timing: A quick look at metrics for LLM serving","permalink":"/blog/llm-serving","unlisted":false},{"title":"When Quantized Models Still Don\'t Fit","permalink":"/blog/quantized-models-dont-fit","unlisted":false},{"title":"What is Ollama? A shallow dive into running LLMs locally","permalink":"/blog/what-is-ollama","unlisted":false}]}')}}]);